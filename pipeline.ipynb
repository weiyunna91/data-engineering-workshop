{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow import DAG\n",
    "from airflow.operators.python import PythonOperator\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_basics = pd.read_csv('data/title.basics.tsv', sep='\\t')\n",
    "title_ratings = pd.read_csv('data/title.ratings.tsv', sep='\\t')\n",
    "title_crew = pd.read_csv('data/title.crew.tsv', sep='\\t')\n",
    "title = pd.read_csv('data/title.akas.tsv', sep='\\t')\n",
    "title_episode = pd.read_csv('data/title.episode.tsv', sep='\\t')\n",
    "title_principals = pd.read_csv('data/title.principals.tsv', sep='\\t')\n",
    "name_basics = pd.read_csv('data/name.basics.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def descriptive_analysis():\n",
    "    title_basics = pd.read_csv('data/title.basics.tsv', sep='\\t')\n",
    "    \n",
    "    # Replace '\\\\N' with NaN\n",
    "    title_basics['startYear'] = title_basics['startYear'].replace('\\\\N', np.nan)\n",
    "    \n",
    "    # Convert to integer, handling NaN values\n",
    "    title_basics['startYear'] = title_basics['startYear'].dropna().astype(int)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    title_basics['titleType'].value_counts().plot(kind='bar')\n",
    "    plt.title('Distribution of Title Types')\n",
    "    plt.xlabel('Title Type')\n",
    "    plt.ylabel('Count')\n",
    "    plt.savefig('output/distribution_title_types.png')\n",
    "    plt.close()\n",
    "\n",
    "    genres_exploded = title_basics['genres'].str.split(',').explode()\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    genres_exploded.value_counts().plot(kind='bar')\n",
    "    plt.title('Distribution of Genres')\n",
    "    plt.xlabel('Genres')\n",
    "    plt.ylabel('Count')\n",
    "    plt.savefig('output/distribution_genres.png')\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    title_basics['startYear'].plot(kind='hist', bins=20)\n",
    "    plt.title('Distribution of Start Years')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.savefig('output/distribution_start_years.png')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptive_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relationship_analysis():\n",
    "    title_basics = pd.read_csv('data/title.basics.tsv', sep='\\t')\n",
    "    title_ratings = pd.read_csv('data/title.ratings.tsv', sep='\\t')\n",
    "    merged_ratings = pd.merge(title_basics, title_ratings, on='tconst', how='inner')\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.scatterplot(data=merged_ratings, x='runtimeMinutes', y='averageRating', hue='genres')\n",
    "    plt.title('Runtime vs. Ratings by Genre')\n",
    "    plt.xlabel('Runtime (Minutes)')\n",
    "    plt.ylabel('Average Rating')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.savefig('output/runtime_vs_ratings.png')\n",
    "    plt.close()\n",
    "\n",
    "    title_crew = pd.read_csv('data/title.crew.tsv', sep='\\t')\n",
    "    crew_ratings = pd.merge(title_crew, title_ratings, on='tconst', how='inner')\n",
    "    crew_ratings['numDirectors'] = crew_ratings['directors'].apply(lambda x: len(x.split(',')) if pd.notnull(x) else 0)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(data=crew_ratings, x='numDirectors', y='averageRating')\n",
    "    plt.title('Number of Directors vs. Ratings')\n",
    "    plt.xlabel('Number of Directors')\n",
    "    plt.ylabel('Average Rating')\n",
    "    plt.savefig('output/directors_vs_ratings.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2024-12-14T10:01:08.222+1100\u001b[0m] {\u001b[34mcategory.py:\u001b[0m223} INFO\u001b[0m - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\u001b[0m\n",
      "[\u001b[34m2024-12-14T10:01:08.533+1100\u001b[0m] {\u001b[34mcategory.py:\u001b[0m223} INFO\u001b[0m - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "relationship_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_analysis():\n",
    "    title_crew = pd.read_csv('data/title.crew.tsv', sep='\\t')\n",
    "    collaborations = []\n",
    "    for _, row in title_crew.iterrows():\n",
    "        if pd.notnull(row['directors']) and pd.notnull(row['writers']):\n",
    "            directors = row['directors'].split(',')\n",
    "            writers = row['writers'].split(',')\n",
    "            collaborations.extend([(d, w) for d in directors for w in writers])\n",
    "\n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from(collaborations)\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    nx.draw(G, node_size=10, alpha=0.7)\n",
    "    plt.title('Director-Writer Collaboration Network')\n",
    "    plt.savefig('output/collaboration_network.png')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#network_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def temporal_analysis():\n",
    "    title_basics = pd.read_csv('data/title.basics.tsv', sep='\\t')\n",
    "    \n",
    "    # Replace '\\\\N' with NaN\n",
    "    title_basics['startYear'] = title_basics['startYear'].replace('\\\\N', np.nan)\n",
    "    \n",
    "    # Convert to integer, handling NaN values\n",
    "    title_basics['startYear'] = title_basics['startYear'].dropna().astype(int)\n",
    "    \n",
    "    genres_by_year = title_basics.dropna(subset=['startYear']).copy()\n",
    "    genres_by_year = genres_by_year.explode('genres').groupby(['startYear', 'genres']).size().unstack(fill_value=0)\n",
    "    genres_by_year.plot.area(figsize=(12, 6), alpha=0.6)\n",
    "    plt.title('Trends in Genres Over Time')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.savefig('output/genres_trends.png')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_comparisons():\n",
    "    title = pd.read_csv('data/title.akas.tsv', sep='\\t')\n",
    "    title_region_genres = title.groupby(['region', 'types']).size().unstack(fill_value=0)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.heatmap(title_region_genres, cmap='viridis')\n",
    "    plt.title('Region vs. Types Popularity')\n",
    "    plt.xlabel('Types')\n",
    "    plt.ylabel('Region')\n",
    "    plt.savefig('output/region_vs_types.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_comparisons()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomaly_detection():\n",
    "    title_ratings = pd.read_csv('data/title.ratings.tsv', sep='\\t')\n",
    "    ratings_outliers = title_ratings[title_ratings['numVotes'] < 100].sort_values(by='averageRating', ascending=False).head(10)\n",
    "    print(\"Highly Rated but Under-Voted Titles:\")\n",
    "    print(ratings_outliers)\n",
    "    ratings_outliers.to_csv('output/highly_rated_under_voted_titles.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highly Rated but Under-Voted Titles:\n",
      "             tconst  averageRating  numVotes\n",
      "1411703   tt7639916           10.0         6\n",
      "1095071  tt30851941           10.0         5\n",
      "1094460  tt30827474           10.0         6\n",
      "1094551  tt30829683           10.0         5\n",
      "1094562  tt30830098           10.0         7\n",
      "1094578  tt30831856           10.0        22\n",
      "1094596  tt30832645           10.0         7\n",
      "1094848  tt30840193           10.0         6\n",
      "1095022  tt30849255           10.0        21\n",
      "808947    tt1683137           10.0        14\n"
     ]
    }
   ],
   "source": [
    "anomaly_detection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for each analysis tas\n",
    "# Define DAG\n",
    "with DAG(\n",
    "    dag_id='data_engineering_workshop_pipeline',\n",
    "    default_args={\n",
    "        'owner': 'airflow',\n",
    "        'depends_on_past': False,\n",
    "        'start_date': datetime(2024, 12, 13),\n",
    "        'retries': 1,\n",
    "    },\n",
    "    schedule_interval=None,\n",
    "    catchup=False\n",
    ") as dag:\n",
    "\n",
    "    task1 = PythonOperator(\n",
    "        task_id='descriptive_analysis',\n",
    "        python_callable=descriptive_analysis\n",
    "    )\n",
    "\n",
    "    task2 = PythonOperator(\n",
    "        task_id='relationship_analysis',\n",
    "        python_callable=relationship_analysis\n",
    "    )\n",
    "\n",
    "    #task3 = PythonOperator(\n",
    "        #task_id='network_analysis',\n",
    "        #python_callable=network_analysis\n",
    "    #)\n",
    "\n",
    "    task4 = PythonOperator(\n",
    "        task_id='temporal_analysis',\n",
    "        python_callable=temporal_analysis\n",
    "    )\n",
    "\n",
    "    task5 = PythonOperator(\n",
    "        task_id='cross_comparisons',\n",
    "        python_callable=cross_comparisons\n",
    "    )\n",
    "\n",
    "    task6 = PythonOperator(\n",
    "        task_id='anomaly_detection',\n",
    "        python_callable=anomaly_detection\n",
    "    )\n",
    "\n",
    "    #task7 = PythonOperator(\n",
    "        #task_id='predictive_analysis',\n",
    "        #python_callable=predictive_analysis\n",
    "    #)\n",
    "\n",
    "    # Set task dependencies\n",
    "    task1 >> [task2, task4, task5, task6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp example_dag.py /path/to/dags\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
